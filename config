pretrained_dir = trained_models/bert-base-uncased

domain_adapt = False
transformation = False
reconstruction = False
semi_supervised = False

train_domain = ['MFTC', 'congress', 'covid', 'eMFD']
test_domain = ['MFTC', 'congress', 'covid', 'eMFD']

n_mf_classes = 10

lr = 0.00003
alpha = 10
beta = 0.25
batch_size = 64
n_epoch = 40
dropout_rate = 0.3
lambda_trans = 0.1
lambda_rec = 1
num_no_adv = 5
gamma = 15

seed = 3
